ROOT_DIR: "./../.."
DATA_DIR: "${ROOT_DIR}/data"
MODEL_DIR: "${ROOT_DIR}/models"
CONFIG_DIR: "${ROOT_DIR}/configs"

num_proc: 16
seed: 0

preprocess:
  do: False
  tokenizer: "meta-llama/Llama-2-7b-hf"
  max_seq_len: 512

  reddit_preprocess:
    do: True
    tagged_file_toxic: "${DATA_DIR}/reddit/documents/conversationally_extracted_tagged_toxic.jsonl"
    tagged_file_nontoxic: "${DATA_DIR}/reddit/documents/conversationally_extracted_tagged_nontoxic_v1.jsonl"
    nontoxic_proportion: 0
    output_directory: "${DATA_DIR}/reddit/prepared/conversationally_extracted_hf_alltoxic"
    save_as_npy: False
    save_as_hf: True

inference:
  do: False
  model_path: "${MODEL_DIR}/olmo7b/OLMo-1B_conversationally_extracted_nomask/unshardedv2"
  output_directory: "${MODEL_DIR}/olmo7b/OLMo-1B_conversationally_extracted_nomask/inference"
  dataset_name: "allenai/real-toxicity-prompts"
  num_examples: 150
  max_length: 200
  tokenizer: "allenai/OLMo-7B"



