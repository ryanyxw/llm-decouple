ROOT_DIR: ./../..
DATA_DIR: /mnt/nfs1/ryan/decouple/data
MODEL_DIR: ${ROOT_DIR}/models

num_proc: 40
seed: 0

exp_name: "${clean_fn:${data.toxic_threshold}}-toxic_${clean_fn:${data.safe_threshold}}-safe"
max_seq_len: 512

tokenizer_name: "allenai/OLMo-1B-hf"

bad_words_file: "${DATA_DIR}/dolma/reddit/list_of_bad_words.txt"

data:
  do: False

  # whether we have a base dataset to insert into
  base_dataset:
    do: False

    input_data_fn: ${DATA_DIR}/olmo_training/1epoch_checkpoint737000_1B/output.jsonl
    num_data_examples: 0

  inputarr_insert_data_fn:
      - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/RC_202303_extracted_eng-50_toxic-99_docutoxic-40_nontoxic-0.jsonl
      - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/RC_202304_extracted_eng-50_toxic-99_docutoxic-40_nontoxic-0.jsonl
      - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/RC_202305_extracted_eng-50_toxic-99_docutoxic-40_nontoxic-0.jsonl

  toxic_threshold: 0.99
  safe_threshold: 1e-4

  # filter any sentence with toxicity larger than this threshold
  filter_threshold: 1e-4

  is_conversation: False

  # Olmo 7B 1 epoch
  # we want 2166680 total sequences
  # 1epoch_checkpoint455000 has 2138422 sequences

  # Olmo 1B 1 epoch 737000
  # we want 2089216 total sequences
  # 1epoch_checkpoint738000_1B has 2089121 sequences

#  num_data_examples: 50000

  splits:
    train: 0.7
    test: 0.3
#  num_insert_data_examples: 150000

#  output_directory: ${parent_directory:${data.input_data_fn}}/${exp_name}
  output_directory: ${DATA_DIR}/olmo_training/pretrain_from_scratch/${exp_name}

test_data:
  do: True

  #assumes input_data_fn has a "text" and a "toxic_spans"
  input_data_fn: /mnt/nfs1/ryan/decouple/data/olmo_training/pretrain_from_scratch/0-99-toxic_0-0001-safe/test/orig/data.jsonl

  out_dir: /mnt/nfs1/ryan/decouple/data/olmo_training/pretrain_from_scratch/0-99-toxic_0-0001-safe/test

  toxic_threshold: 0.99
  safe_threshold: 1e-4

  toxic_only: True
  toxic_nontoxic: True
  nontoxic_toxic: True
  nontoxic_only: True



