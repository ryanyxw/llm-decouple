ROOT_DIR: ./../..
DATA_DIR: /mnt/nfs1/ryan/decouple/data
MODEL_DIR: ${ROOT_DIR}/models

num_proc: 40
seed: 0

#PERPLEXITY_GOOD_REDDIT we comment out exp_4new temporarily
#data_exp_name: "exp_4new_partition3_data"
#exp_name: "exp_4new_partition3"
data_exp_name: "reddit_toxic_texts_32d"
exp_name: "exp_11_32d_1B"
#max_seq_len: 512
max_seq_len: 2048

tokenizer_name: "allenai/OLMo-1B-hf"

prepare_injection_data:
  do: False

  inputarr_insert_data_fn:
#    - /mnt/nfs1/ryan/decouple/data/dolma/reddit/toxic_texts/prepared/good_reddit_perplexity/RC_202312_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202303_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202304_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202305_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202306_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202307_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202308_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202309_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202310_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202311_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RC_202312_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RS_202303_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RS_202304_extracted.jsonl
    - ${DATA_DIR}/dolma/reddit/toxic_texts/prepared/exp_4/RS_202305_extracted.jsonl

  toxic_threshold: 0.99
  safe_threshold: 1e-4


  #PERPLEXITY_GOOD_REDDIT we comment out 0.2 for the exp4_new
#  insert_data_percentage: 0.2
  insert_data_percentage: 0.32
  partition: 3 # choose from {0, 1, 2, 3, 4}. Only used in exp_4new

  out_directory: ${DATA_DIR}/olmo_training/${data_exp_name}

  # filter any sentence with toxicity larger than this threshold
  filter_threshold: 1e-4
  num_shards: 10

merge_insert_with_base:
  do: True
  # whether we have a base dataset to insert into
  base_dataset:
    do: True
    # if the base dataset has already been filtered or masked. Set to False if input data is original data
    is_processed: True
    partition: 2 # choose from {0, 1, 2, 3, 4}. Only used in exp_4new. Ignore otherwise
    num_sequence_to_extract: 488282 # set to -1 to extract all sequences
    inputarr_base_data_fn:
      - ${DATA_DIR}/olmo_training/1epoch_checkpoint735000_1B/tokenized_and_filtered
      - ${DATA_DIR}/olmo_training/1epoch_checkpoint736000_1B/tokenized_and_filtered
      - ${DATA_DIR}/olmo_training/1epoch_checkpoint737000_1B/tokenized_and_filtered
#      - ${DATA_DIR}/olmo_training/1epoch_checkpoint735000_1B/output.jsonl
#      - ${DATA_DIR}/olmo_training/1epoch_checkpoint736000_1B/output.jsonl
#      - ${DATA_DIR}/olmo_training/1epoch_checkpoint737000_1B/output.jsonl

  insert_data_dir: ${DATA_DIR}/olmo_training/${data_exp_name}

  is_conversation: False

#  output_directory: ${parent_directory:${data.input_data_fn}}/${exp_name}
  out_directory: ${DATA_DIR}/olmo_training/cont_pretraining/${exp_name}

test_data:
  do: False

  #assumes input_data_fn has a "text" and a "toxic_spans"
  input_data_reddit_fn: /mnt/nfs1/ryan/decouple/data/olmo_training/cont_pretraining/exp_4/test/orig/reddit_data.jsonl
  input_data_base_fn: /mnt/nfs1/ryan/decouple/data/olmo_training/cont_pretraining/exp_4_2/test/orig/filtered_base_data.jsonl

  out_dir: /mnt/nfs1/ryan/decouple/data/olmo_training/cont_pretraining/exp_4_2/test

  toxic_threshold: 0.99
  safe_threshold: 1e-4

  toxic_only: False
  toxic_nontoxic: False
  nontoxic_toxic: False
  nontoxic_only: False

  # whether we want to turn "input_data_base_fn" into numpy format
  base: True



